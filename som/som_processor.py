#!/usr/bin/env python3
"""
SoMå¤„ç†å™¨ - åŸºäºOmniParser-v2.0
ç®€æ´ç‰ˆæœ¬ï¼Œä¸“é—¨ç”¨äºç”ŸæˆSet-of-Markæ ‡æ³¨
"""

import os
import io
import base64
import torch
import numpy as np
from PIL import Image
from huggingface_hub import snapshot_download

# OmniParser imports
from som import MarkHelper, plot_boxes_with_marks
from utils import get_yolo_model, get_som_labeled_img, check_ocr_box

class SoMProcessor:
    def __init__(self):
        self.setup_models()
        self.mark_helper = MarkHelper()
    
    def setup_models(self):
        """ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹"""
        # ä¸‹è½½æƒé‡
        if not os.path.exists('./weights/icon_detect/model.pt'):
            print("ğŸ“¦ Downloading OmniParser weights...")
            snapshot_download(
                repo_id="microsoft/OmniParser-v2.0", 
                local_dir='./weights'
            )
        
        # åŠ è½½YOLOæ¨¡å‹
        self.yolo_model = get_yolo_model(model_path='./weights/icon_detect/model.pt')
        print("âœ… Models loaded")
    
    def process_image(self, image, box_threshold=0.01, ocr_threshold=0.9):
        """å¤„ç†å•å¼ å›¾åƒï¼Œè¿”å›SoMæ ‡æ³¨"""
        
        # è‡ªé€‚åº”å‚æ•°
        box_overlay_ratio = image.size[0] / 3200
        draw_config = {
            # 'text_scale': 0.8 * box_overlay_ratio,
            'text_scale': 0.9,
            'text_thickness': max(int(2 * box_overlay_ratio), 2),
            'text_padding': max(int(3 * box_overlay_ratio), 2),
            'thickness': max(int(3 * box_overlay_ratio), 2),   
        }
        
        
        # OCRæ£€æµ‹
        ocr_result, _ = check_ocr_box(
            image, 
            display_img=False,
            output_bb_format='xyxy',
            easyocr_args={'paragraph': False, 'text_threshold': ocr_threshold},
            use_paddleocr=False
        )
        text, ocr_bbox = ocr_result
        
        # ç”ŸæˆSoM
        labeled_img_b64, coordinates, _ = get_som_labeled_img(
            image,
            self.yolo_model,
            BOX_TRESHOLD=box_threshold,
            output_coord_in_ratio=False,
            ocr_bbox=ocr_bbox,
            draw_bbox_config=draw_config,
            caption_model_processor=None,  # ä¸ä½¿ç”¨caption
            ocr_text=text,
            use_local_semantics=False,     # è·³è¿‡è¯­ä¹‰ç†è§£
            iou_threshold=0.9
        )
        
        # è§£ç å›¾åƒ
        som_image = Image.open(io.BytesIO(base64.b64decode(labeled_img_b64)))
        
        return som_image, coordinates